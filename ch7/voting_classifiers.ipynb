{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 투표 기반 분류기(Voting Classifier)\n",
    "\n",
    "### 직접 투표(hard voting)\n",
    "직접투표(hard voting)이란, 다수결 투표처럼, 여러 분류기들이 예측한 결과에서, 가장 많이 선택된 클래스를 예측하는 방법을 의미한다.\n",
    "\n",
    "<br/>\n",
    "<img src=\"./images/hard_voting.png\" alt=\"hard_voting\">\n",
    "<br/>\n",
    "\n",
    "*그림 출처 : https://devkor.tistory.com/entry/Soft-Voting-%EA%B3%BC-Hard-Voting*\n",
    "\n",
    "### 큰 수의 법칙(law of large numbers)\n",
    "앞면이 51%, 뒷면이 49%의 확률로 나오는 동전이 있다고 했을 때, 동전을 1000번 던질 경우, 앞면이 다수가 될 확률은 약 75%가 된다.\n",
    "\n",
    "이는 이항분포의 PMF(확률질량함수)를 구해 CDF(누적분포함수)를 계산해보면 약 0.747의 결과가 나온다는 것을 알 수 있다. 자세한 계산은 다음과 같다.\n",
    "\n",
    "확률이 p인 이항분포에서, n번의 시도 중 k번 성공할 확률은 다음과 같다.\n",
    "\n",
    "$$\\dfrac{n}{k}p^k(1-p)^{(n-k)}$$\n",
    "\n",
    "따라서, 성공 확률이 51%인 동전을 1000번 던져 앞면이 한번만 나올 확률은 다음과 같으며,\n",
    "\n",
    "\n",
    "$$\\dfrac{1000}{1}0.51^1(1-0.51)^{(1000-1)} = 1.6 \\times 10^{()-307}$$\n",
    "\n",
    "이를 1000의 과반 직전인 499까지의 확률을 모두 더한 후, 전체 확률 1에서 빼면, 1000번 던져서 앞면이 더 많이 나올 확률이 된다.\n",
    "\n",
    "`scipy`를 사용하면 이항분포의 CDF를 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7467502275561786\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "print(1-binom.cdf(499, 1000, 0.51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서, 51%의 정확도를 가진 1000개의 분류기로 앙상블을 한다면, 75%의 정확도를 얻을 수 있다. (단, 모든 분류기는 완벽히 독립적이고, 오차에 상관관계가 없어야 함)\n",
    "\n",
    "앙상블 방법은 predictor가 가능한 서로 독립적일 때 가장 큰 성능을 발휘할 수 있다. 각기 다른 알고리즘으로 학습시킨다면, 서로 다른 종류의 오차를 만들 가능성이 높기 때문에 앙상블 모델의 성능을 높일 수 있다.\n",
    "\n",
    "사이킷런에서는 `VotingClassifier`를 통해 voting classifier를 구현할 수 있다. 다음은 moons dataset을 이용한 예이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     cr...\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  decision_function_shape='ovr', degree=3,\n",
       "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                                  probability=False, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 분류기와 앙상블한 분류기의 테스트셋에서의 정확도는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간접 투표 (soft voting)\n",
    "\n",
    "간접 투표(soft voting)이란, 여러 분류기들이 예측한 확률을 합산해서 가장 높은 확률의 class를 예측하는 방법을 의미한다. \n",
    "\n",
    "<br/>\n",
    "<img src=\"./images/soft_voting.png\" alt=\"soft_voting\">\n",
    "<br/>\n",
    "\n",
    "*그림 출처 : https://devkor.tistory.com/entry/Soft-Voting-%EA%B3%BC-Hard-Voting*\n",
    "\n",
    "soft voting은 확률이 높은 예측에 더 비중을 두기 때문에, hard voting보다 성능이 높다.\n",
    "\n",
    "사이킷런에서는 `predict_proba()`가 있는 classifier의 경우 사용이 가능하며, `voting=\"soft\"`를 지정해 주면 된다.\n",
    "\n",
    "다음은 soft voting의 예이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "# `SVC`에서 predict_proba()를 사용하기 위해 probability=True를 설정해줌\n",
    "svm_clf = SVC(probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    # soft voting 설정 \n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
